{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Short-Answer-Questions\" data-toc-modified-id=\"Short-Answer-Questions-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Short Answer Questions</a></span></li><li><span><a href=\"#Part-1:-KNN-+-Pipelines-[Suggested-time:-20-minutes]\" data-toc-modified-id=\"Part-1:-KNN-+-Pipelines-[Suggested-time:-20-minutes]-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Part 1: KNN + Pipelines [Suggested time: 20 minutes]</a></span><ul class=\"toc-item\"><li><span><a href=\"#1.1)-Short-Answer:-What-fact-about-the-KNN-algorithm-makes-it-necessary-to-standard-scale-the-features?-Explain.\" data-toc-modified-id=\"1.1)-Short-Answer:-What-fact-about-the-KNN-algorithm-makes-it-necessary-to-standard-scale-the-features?-Explain.-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>1.1) Short Answer: What fact about the KNN algorithm makes it necessary to standard scale the features? Explain.</a></span></li><li><span><a href=\"#1.2)-Short-Answer:-We'll-be-setting-up-a-Pipeline-to-do-the-imputation,-scaling,-and-then-passing-the-data-on-to-the-KNN-model.-What-problem-can-pipelines-help-avoid-during-cross-validation?\" data-toc-modified-id=\"1.2)-Short-Answer:-We'll-be-setting-up-a-Pipeline-to-do-the-imputation,-scaling,-and-then-passing-the-data-on-to-the-KNN-model.-What-problem-can-pipelines-help-avoid-during-cross-validation?-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>1.2) Short Answer: We'll be setting up a Pipeline to do the imputation, scaling, and then passing the data on to the KNN model. What problem can pipelines help avoid during cross-validation?</a></span></li><li><span><a href=\"#1.3)-Conduct-a-70-30-train-test-split.-Use-a-random_state-of-42-for-the-train_test_split.-Save-the-train-and-test-set-features-to-X_train,-X_test-respectively.-Save-the-train-and-test-set-labels-to-y_train,-y_test-respectively.\" data-toc-modified-id=\"1.3)-Conduct-a-70-30-train-test-split.-Use-a-random_state-of-42-for-the-train_test_split.-Save-the-train-and-test-set-features-to-X_train,-X_test-respectively.-Save-the-train-and-test-set-labels-to-y_train,-y_test-respectively.-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>1.3) Conduct a 70-30 train-test split. Use a <code>random_state</code> of 42 for the train_test_split. Save the train and test set features to X_train, X_test respectively. Save the train and test set labels to y_train, y_test respectively.</a></span></li><li><span><a href=\"#1.4)-Train/fit-the-pipeline-and-evaluate-accuracy-on-the-test-set.-Save-your-predicted-values-on-the-test-set-to-y_pred.-Save-your-computed-test-accuracy-score-to-the-variable-test_acc.\" data-toc-modified-id=\"1.4)-Train/fit-the-pipeline-and-evaluate-accuracy-on-the-test-set.-Save-your-predicted-values-on-the-test-set-to-y_pred.-Save-your-computed-test-accuracy-score-to-the-variable-test_acc.-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>1.4) Train/fit the pipeline and evaluate accuracy on the test set. Save your predicted values on the test set to <code>y_pred</code>. Save your computed test accuracy score to the variable <code>test_acc</code>.</a></span></li><li><span><a href=\"#1.5)-Create-a-GridSearchCV-on-the-pipeline-and-save-it-to-an-object-called-grid_knn:\" data-toc-modified-id=\"1.5)-Create-a-GridSearchCV-on-the-pipeline-and-save-it-to-an-object-called-grid_knn:-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>1.5) Create a GridSearchCV on the pipeline and save it to an object called <code>grid_knn</code>:</a></span></li><li><span><a href=\"#1.6)-Retrain-best_pipe-(your-best-model-from-cross-validation)-on-your-entire-train-set-and-predict-on-the-true-hold-out-test-set.\" data-toc-modified-id=\"1.6)-Retrain-best_pipe-(your-best-model-from-cross-validation)-on-your-entire-train-set-and-predict-on-the-true-hold-out-test-set.-2.6\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span>1.6) Retrain <code>best_pipe</code> (your best model from cross validation) on your entire train set and predict on the true hold-out test set.</a></span></li></ul></li><li><span><a href=\"#Part-2:-Ensembles-&amp;-Boosting-[Suggested-time:-5-minutes]\" data-toc-modified-id=\"Part-2:-Ensembles-&amp;-Boosting-[Suggested-time:-5-minutes]-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Part 2: Ensembles &amp; Boosting [Suggested time: 5 minutes]</a></span><ul class=\"toc-item\"><li><span><a href=\"#2.1)-Short-Answer:-Identify-the-two-main-methods-of-randomization-used-in-random-forests.-How-are-these-methods-employed-in-the-random-forest-algorithm,-and-how-do-they-help-to-combat-the-high-variance-that-tends-to-characterize-decision-tree-models?\" data-toc-modified-id=\"2.1)-Short-Answer:-Identify-the-two-main-methods-of-randomization-used-in-random-forests.-How-are-these-methods-employed-in-the-random-forest-algorithm,-and-how-do-they-help-to-combat-the-high-variance-that-tends-to-characterize-decision-tree-models?-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>2.1) Short Answer: Identify the two main methods of randomization used in random forests. How are these methods employed in the random forest algorithm, and how do they help to combat the high variance that tends to characterize decision-tree models?</a></span></li><li><span><a href=\"#2.2)-Short-Answer:-In-order-to-get-a-random-forest-that-generalizes-well,-it's-typically-necessary-to-tune-some-hyperparameters.-In-the-language-of-Sklearn's-implementation,-one-of-the-most-relevant-hyperparameters-is-max_depth.-Describe-this-hyperparameter-and-how-it-can-factor-into-model-performance.\" data-toc-modified-id=\"2.2)-Short-Answer:-In-order-to-get-a-random-forest-that-generalizes-well,-it's-typically-necessary-to-tune-some-hyperparameters.-In-the-language-of-Sklearn's-implementation,-one-of-the-most-relevant-hyperparameters-is-max_depth.-Describe-this-hyperparameter-and-how-it-can-factor-into-model-performance.-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>2.2) Short Answer: In order to get a random forest that generalizes well, it's typically necessary to tune some hyperparameters. In the language of Sklearn's implementation, one of the most relevant hyperparameters is <code>max_depth</code>. Describe this hyperparameter and how it can factor into model performance.</a></span></li></ul></li><li><span><a href=\"#Part-3:-Natural-Language-Processing-[Suggested-time:-20-minutes]\" data-toc-modified-id=\"Part-3:-Natural-Language-Processing-[Suggested-time:-20-minutes]-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Part 3: Natural Language Processing [Suggested time: 20 minutes]</a></span><ul class=\"toc-item\"><li><span><a href=\"#3.1)-Short-Answer:-Explain-why-stop-word-removal-might-be-a-useful-preprocessing-step-prior-to-any-given-predictive-task.\" data-toc-modified-id=\"3.1)-Short-Answer:-Explain-why-stop-word-removal-might-be-a-useful-preprocessing-step-prior-to-any-given-predictive-task.-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>3.1) Short Answer: Explain why stop word removal might be a useful preprocessing step prior to any given predictive task.</a></span></li><li><span><a href=\"#3.2)-Short-Answer:-Explain,-in-your-own-words,-how-the-TF-IDF-vectorizer-assigns-weights-to-features-(tokens)-in-a-given-document.-What-would-a-high-score-mean-for-a-particular-word-&amp;-document-pair.\" data-toc-modified-id=\"3.2)-Short-Answer:-Explain,-in-your-own-words,-how-the-TF-IDF-vectorizer-assigns-weights-to-features-(tokens)-in-a-given-document.-What-would-a-high-score-mean-for-a-particular-word-&amp;-document-pair.-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>3.2) Short Answer: Explain, in your own words, how the TF-IDF vectorizer assigns weights to features (tokens) in a given document. What would a high score mean for a particular word &amp; document pair.</a></span></li><li><span><a href=\"#3.3)-Save-the-relevant-text-and-target-to-X_sent,-y_sent.-Use-the-preprocessed_test-column-created-above.-Train/test-split-with-a-random_state-=-42.-Use-a-70-30-train-test-split-and-save-to-the-relevant-variables-below.\" data-toc-modified-id=\"3.3)-Save-the-relevant-text-and-target-to-X_sent,-y_sent.-Use-the-preprocessed_test-column-created-above.-Train/test-split-with-a-random_state-=-42.-Use-a-70-30-train-test-split-and-save-to-the-relevant-variables-below.-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>3.3) Save the relevant text and target to X_sent, y_sent. Use the <code>preprocessed_test</code> column created above. Train/test split with a random_state = 42. Use a 70-30 train-test split and save to the relevant variables below.</a></span></li><li><span><a href=\"#3.4)-Create-a-pipeline-that-TF-IDF-vectorizes-text-input-and-then-feeds-it-into-a-Multinomial-Naive-Bayes-classifier.-Ensure-that-tokens-that-are-in-less-than-1%-of-the-documents-and-in-more-than-90%-of-the-documents-are-filtered-out-by-our-pipeline.-Save-the-pipeline-as-a-variable-nlp_pipe.\" data-toc-modified-id=\"3.4)-Create-a-pipeline-that-TF-IDF-vectorizes-text-input-and-then-feeds-it-into-a-Multinomial-Naive-Bayes-classifier.-Ensure-that-tokens-that-are-in-less-than-1%-of-the-documents-and-in-more-than-90%-of-the-documents-are-filtered-out-by-our-pipeline.-Save-the-pipeline-as-a-variable-nlp_pipe.-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>3.4) Create a pipeline that TF-IDF vectorizes text input and then feeds it into a Multinomial Naive Bayes classifier. Ensure that tokens that are in less than 1% of the documents and in more than 90% of the documents are filtered out by our pipeline. Save the pipeline as a variable <strong>nlp_pipe</strong>.</a></span></li><li><span><a href=\"#3.5)-Train-the-pipeline-and-then-predict-on-the-test-set.-Save-predicted-test-values-as-y_sent_pred-and-then-evaluate-the-test-accuracy-score.\" data-toc-modified-id=\"3.5)-Train-the-pipeline-and-then-predict-on-the-test-set.-Save-predicted-test-values-as-y_sent_pred-and-then-evaluate-the-test-accuracy-score.-4.5\"><span class=\"toc-item-num\">4.5&nbsp;&nbsp;</span>3.5) Train the pipeline and then predict on the test set. Save predicted test values as y_sent_pred and then evaluate the test accuracy score.</a></span></li><li><span><a href=\"#3.6)-Evaluate-a-confusion-matrix-on-the-predictions-of-the-test-set-and-save-it-to-the-variable-cfm.-Uncomment-the-confusion-matrix-display-code-to-show.\" data-toc-modified-id=\"3.6)-Evaluate-a-confusion-matrix-on-the-predictions-of-the-test-set-and-save-it-to-the-variable-cfm.-Uncomment-the-confusion-matrix-display-code-to-show.-4.6\"><span class=\"toc-item-num\">4.6&nbsp;&nbsp;</span>3.6) Evaluate a confusion matrix on the predictions of the test set and save it to the variable <strong>cfm</strong>. Uncomment the confusion matrix display code to show.</a></span></li><li><span><a href=\"#3.7)-Short-Answer:-Looking-at-the-confusion-matrix-above,-comment-on-how-well-the-model-is-generalizing-to-the-testing-data.\" data-toc-modified-id=\"3.7)-Short-Answer:-Looking-at-the-confusion-matrix-above,-comment-on-how-well-the-model-is-generalizing-to-the-testing-data.-4.7\"><span class=\"toc-item-num\">4.7&nbsp;&nbsp;</span>3.7) Short Answer: Looking at the confusion matrix above, comment on how well the model is generalizing to the testing data.</a></span></li></ul></li><li><span><a href=\"#Part-4:-Clustering-[Suggested-time:-20-minutes]\" data-toc-modified-id=\"Part-4:-Clustering-[Suggested-time:-20-minutes]-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Part 4: Clustering [Suggested time: 20 minutes]</a></span><ul class=\"toc-item\"><li><span><a href=\"#4.1)-Short-Answer:-In-the-context-of-clustering,-what-is-a-centroid?\" data-toc-modified-id=\"4.1)-Short-Answer:-In-the-context-of-clustering,-what-is-a-centroid?-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>4.1) Short Answer: In the context of clustering, what is a centroid?</a></span></li><li><span><a href=\"#4.2)-Short-Answer:-KMeans-is-an-algorithm-used-for-clustering-data-that-first-randomly-intializes-$K$-centroids-and-then-use-a-two-step-iterative-process-(coordinate-descent)-to-minimize-the-inertia-cost-function-until-convergence-has-been-achieved.-What-two-steps-are-executed-during-each-K-Means-iteration?\" data-toc-modified-id=\"4.2)-Short-Answer:-KMeans-is-an-algorithm-used-for-clustering-data-that-first-randomly-intializes-$K$-centroids-and-then-use-a-two-step-iterative-process-(coordinate-descent)-to-minimize-the-inertia-cost-function-until-convergence-has-been-achieved.-What-two-steps-are-executed-during-each-K-Means-iteration?-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>4.2) Short Answer: KMeans is an algorithm used for clustering data that first randomly intializes $K$ centroids and then use a two-step iterative process (coordinate descent) to minimize the inertia cost function until convergence has been achieved. What two steps are executed during each K-Means iteration?</a></span></li><li><span><a href=\"#4.3)-Fit-a-StandardScaler-to-the-data-and-then-fit-a-KMeans-clustering-model,-for-K-=-3,-to-the-scaled-data.-Use-a-random_state-of-42-for-KMeans.\" data-toc-modified-id=\"4.3)-Fit-a-StandardScaler-to-the-data-and-then-fit-a-KMeans-clustering-model,-for-K-=-3,-to-the-scaled-data.-Use-a-random_state-of-42-for-KMeans.-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>4.3) Fit a <code>StandardScaler</code> to the data and then fit a KMeans clustering model, for K = 3, to the scaled data. Use a <code>random_state</code> of 42 for KMeans.</a></span></li><li><span><a href=\"#4.4)-Evaluate-cluster-assignments-for-these-datapoints.-Create-a-new-dataframe-data_scaled_df-that-includes-your-scaled-data-and-a-new-column-called-&quot;cluster_label&quot;-that-indicates-the-cluster-assignments.\" data-toc-modified-id=\"4.4)-Evaluate-cluster-assignments-for-these-datapoints.-Create-a-new-dataframe-data_scaled_df-that-includes-your-scaled-data-and-a-new-column-called-&quot;cluster_label&quot;-that-indicates-the-cluster-assignments.-5.4\"><span class=\"toc-item-num\">5.4&nbsp;&nbsp;</span>4.4) Evaluate cluster assignments for these datapoints. Create a new dataframe <code>data_scaled_df</code> that includes your scaled data and a new column called \"cluster_label\" that indicates the cluster assignments.</a></span></li><li><span><a href=\"#4.5)-Below-we-have-provided-code-to-loop-through-a-few-values-of-$k$-from-$k=3$-to-$k=9$.-We-fit-KMeans-data-for-each-value-of-$k$-and-generate-cluster-labels.-Your-job-is-to-compute-the-Silhouette-Score-for-each-value-of-$k$-and-add-it-to-the-the-km_dict-dictionary.-Use-$k$-as-your-dictionary-key-and-the-corresponding-score-as-your-value.\" data-toc-modified-id=\"4.5)-Below-we-have-provided-code-to-loop-through-a-few-values-of-$k$-from-$k=3$-to-$k=9$.-We-fit-KMeans-data-for-each-value-of-$k$-and-generate-cluster-labels.-Your-job-is-to-compute-the-Silhouette-Score-for-each-value-of-$k$-and-add-it-to-the-the-km_dict-dictionary.-Use-$k$-as-your-dictionary-key-and-the-corresponding-score-as-your-value.-5.5\"><span class=\"toc-item-num\">5.5&nbsp;&nbsp;</span>4.5) Below we have provided code to loop through a few values of $k$ from $k=3$ to $k=9$. We fit KMeans data for each value of $k$ and generate cluster labels. Your job is to compute the Silhouette Score for each value of $k$ and add it to the the <code>km_dict</code> dictionary. Use $k$ as your dictionary key and the corresponding score as your value.</a></span></li><li><span><a href=\"#4.6)-Short-Answer:-Based-on-the-above-plot,-how-many-customer-clusters-does-the-SS-metric-suggest-our-data-is-most-likely-explained-by?\" data-toc-modified-id=\"4.6)-Short-Answer:-Based-on-the-above-plot,-how-many-customer-clusters-does-the-SS-metric-suggest-our-data-is-most-likely-explained-by?-5.6\"><span class=\"toc-item-num\">5.6&nbsp;&nbsp;</span>4.6) Short Answer: Based on the above plot, how many customer clusters does the SS metric suggest our data is most likely explained by?</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 4 Code Challenge\n",
    "This code challenge is designed to test your understanding of the Phase 1 material. It covers:\n",
    "\n",
    "- KNN & Pipelines\n",
    "- Ensemble & Boosting\n",
    "- Natural Langauge Processing\n",
    "- Clustering\n",
    "\n",
    "*Read the instructions carefully.* Your code will need to meet detailed specifications to pass automated tests.\n",
    "\n",
    "## Short Answer Questions \n",
    "\n",
    "For the short answer questions...\n",
    "\n",
    "* _Use your own words_. It is OK to refer to outside resources when crafting your response, but _do not copy text from another source_.\n",
    "\n",
    "* _Communicate clearly_. We are not grading your writing skills, but you can only receive full credit if your teacher is able to fully understand your response. \n",
    "\n",
    "* _Be concise_. You should be able to answer most short answer questions in a sentence or two. Writing unnecessarily long answers increases the risk of you being unclear or saying something incorrect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Run this cell without changes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, silhouette_score\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: KNN + Pipelines [Suggested time: 20 minutes]\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are given a dataset containing various physical characteristics of the seeds of three distinct species of wheat. Your job will be to tune/train a KNN classifier that can predict the species based on the provided features.\n",
    "\n",
    "Load in the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>Perimeter</th>\n",
       "      <th>Compactness</th>\n",
       "      <th>Kernel.Length</th>\n",
       "      <th>Kernel.Width</th>\n",
       "      <th>Asymmetry.Coeff</th>\n",
       "      <th>Kernel.Groove</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.26</td>\n",
       "      <td>14.84</td>\n",
       "      <td>0.8710</td>\n",
       "      <td>5.763</td>\n",
       "      <td>3.312</td>\n",
       "      <td>2.221</td>\n",
       "      <td>5.220</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.88</td>\n",
       "      <td>14.57</td>\n",
       "      <td>0.8811</td>\n",
       "      <td>5.554</td>\n",
       "      <td>3.333</td>\n",
       "      <td>1.018</td>\n",
       "      <td>4.956</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.29</td>\n",
       "      <td>14.09</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>5.291</td>\n",
       "      <td>3.337</td>\n",
       "      <td>2.699</td>\n",
       "      <td>4.825</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.84</td>\n",
       "      <td>13.94</td>\n",
       "      <td>0.8955</td>\n",
       "      <td>5.324</td>\n",
       "      <td>3.379</td>\n",
       "      <td>2.259</td>\n",
       "      <td>4.805</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.14</td>\n",
       "      <td>14.99</td>\n",
       "      <td>0.9034</td>\n",
       "      <td>5.658</td>\n",
       "      <td>3.562</td>\n",
       "      <td>1.355</td>\n",
       "      <td>5.175</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Area  Perimeter  Compactness  Kernel.Length  Kernel.Width  \\\n",
       "0  15.26      14.84       0.8710          5.763         3.312   \n",
       "1  14.88      14.57       0.8811          5.554         3.333   \n",
       "2  14.29      14.09       0.9050          5.291         3.337   \n",
       "3  13.84      13.94       0.8955          5.324         3.379   \n",
       "4  16.14      14.99       0.9034          5.658         3.562   \n",
       "\n",
       "   Asymmetry.Coeff  Kernel.Groove  Type  \n",
       "0            2.221          5.220     1  \n",
       "1            1.018          4.956     1  \n",
       "2            2.699          4.825     1  \n",
       "3            2.259          4.805     1  \n",
       "4            1.355          5.175     1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this cell without changes to load in data\n",
    "wheat_df = pd.read_csv('wheat_seeds.csv')\n",
    "wheat_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect this dataframe and its statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 199 entries, 0 to 198\n",
      "Data columns (total 8 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Area             199 non-null    float64\n",
      " 1   Perimeter        199 non-null    float64\n",
      " 2   Compactness      174 non-null    float64\n",
      " 3   Kernel.Length    199 non-null    float64\n",
      " 4   Kernel.Width     199 non-null    float64\n",
      " 5   Asymmetry.Coeff  199 non-null    float64\n",
      " 6   Kernel.Groove    199 non-null    float64\n",
      " 7   Type             199 non-null    int64  \n",
      "dtypes: float64(7), int64(1)\n",
      "memory usage: 12.6 KB\n"
     ]
    }
   ],
   "source": [
    "# Run this cell without changing\n",
    "wheat_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>Perimeter</th>\n",
       "      <th>Compactness</th>\n",
       "      <th>Kernel.Length</th>\n",
       "      <th>Kernel.Width</th>\n",
       "      <th>Asymmetry.Coeff</th>\n",
       "      <th>Kernel.Groove</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>199.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>174.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>199.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.918744</td>\n",
       "      <td>14.595829</td>\n",
       "      <td>0.869909</td>\n",
       "      <td>5.643151</td>\n",
       "      <td>3.265533</td>\n",
       "      <td>3.699217</td>\n",
       "      <td>5.420653</td>\n",
       "      <td>1.994975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.919976</td>\n",
       "      <td>1.310445</td>\n",
       "      <td>0.023447</td>\n",
       "      <td>0.443593</td>\n",
       "      <td>0.378322</td>\n",
       "      <td>1.471102</td>\n",
       "      <td>0.492718</td>\n",
       "      <td>0.813382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>10.590000</td>\n",
       "      <td>12.410000</td>\n",
       "      <td>0.808100</td>\n",
       "      <td>4.899000</td>\n",
       "      <td>2.630000</td>\n",
       "      <td>0.765100</td>\n",
       "      <td>4.519000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>12.330000</td>\n",
       "      <td>13.470000</td>\n",
       "      <td>0.856675</td>\n",
       "      <td>5.267000</td>\n",
       "      <td>2.954500</td>\n",
       "      <td>2.570000</td>\n",
       "      <td>5.046000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>14.430000</td>\n",
       "      <td>14.370000</td>\n",
       "      <td>0.872300</td>\n",
       "      <td>5.541000</td>\n",
       "      <td>3.245000</td>\n",
       "      <td>3.631000</td>\n",
       "      <td>5.228000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>17.455000</td>\n",
       "      <td>15.805000</td>\n",
       "      <td>0.885625</td>\n",
       "      <td>6.002000</td>\n",
       "      <td>3.564500</td>\n",
       "      <td>4.799000</td>\n",
       "      <td>5.879000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>21.180000</td>\n",
       "      <td>17.250000</td>\n",
       "      <td>0.918300</td>\n",
       "      <td>6.675000</td>\n",
       "      <td>4.033000</td>\n",
       "      <td>8.315000</td>\n",
       "      <td>6.550000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Area   Perimeter  Compactness  Kernel.Length  Kernel.Width  \\\n",
       "count  199.000000  199.000000   174.000000     199.000000    199.000000   \n",
       "mean    14.918744   14.595829     0.869909       5.643151      3.265533   \n",
       "std      2.919976    1.310445     0.023447       0.443593      0.378322   \n",
       "min     10.590000   12.410000     0.808100       4.899000      2.630000   \n",
       "25%     12.330000   13.470000     0.856675       5.267000      2.954500   \n",
       "50%     14.430000   14.370000     0.872300       5.541000      3.245000   \n",
       "75%     17.455000   15.805000     0.885625       6.002000      3.564500   \n",
       "max     21.180000   17.250000     0.918300       6.675000      4.033000   \n",
       "\n",
       "       Asymmetry.Coeff  Kernel.Groove        Type  \n",
       "count       199.000000     199.000000  199.000000  \n",
       "mean          3.699217       5.420653    1.994975  \n",
       "std           1.471102       0.492718    0.813382  \n",
       "min           0.765100       4.519000    1.000000  \n",
       "25%           2.570000       5.046000    1.000000  \n",
       "50%           3.631000       5.228000    2.000000  \n",
       "75%           4.799000       5.879000    3.000000  \n",
       "max           8.315000       6.550000    3.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this cell without changing\n",
    "wheat_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few NaNs in the compactness column and a quick look at the summary statistics reveal that the mean and variance for some of the features are significantly different. We are going to simple impute the NaN with the mean and standard scale the features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1) Short Answer: What fact about the KNN algorithm makes it necessary to standard scale the features? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your answer here\n",
    "\n",
    "`KNN is distance based algorithm and therefore affected by the scale of the variables and hence the need to bring all variables to the same scale`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2) Short Answer: We'll be setting up a Pipeline to do the imputation, scaling, and then passing the data on to the KNN model. What problem can pipelines help avoid during cross-validation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your answer here\n",
    "\n",
    "`Prevents data leakage`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll create a pipeline that performs a couple transformations before passing the data to a KNN estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "steps = [('imp', SimpleImputer(strategy='mean')),\n",
    "         ('scaler', StandardScaler()),\n",
    "         ('knn', KNeighborsClassifier(n_neighbors=30))]\n",
    "pipe = Pipeline(steps) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3) Conduct a 70-30 train-test split. Use a `random_state` of 42 for the train_test_split. Save the train and test set features to X_train, X_test respectively. Save the train and test set labels to y_train, y_test respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CodeGrade step1.1\n",
    "# Replace None with appropriate code\n",
    "# do the required data splitting here\n",
    "\n",
    "# Assign X and y, use all columns but y for X\n",
    "X = wheat_df.drop(columns='Type')\n",
    "y = wheat_df['Type']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick perusal shows that the train set is fairly balanced. We'll thus use classification accuracy as our metric for evaluating our train/test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    68\n",
       "1    66\n",
       "3    65\n",
       "Name: Type, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this cell without changes\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4) Train/fit the pipeline and evaluate accuracy on the test set. Save your predicted values on the test set to `y_pred`. Save your computed test accuracy score to the variable `test_acc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8833333333333333"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CodeGrade step1.2\n",
    "# Replace None with appropriate code\n",
    "\n",
    "# Fit pipeline\n",
    "pipe.fit(X_train,y_train)\n",
    "\n",
    "# Test set predictions and accuracy score\n",
    "y_pred = pipe.predict(X_test)\n",
    "test_acc = pipe.score(X_test,y_test)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning the hyperparameters of the transformers and estimators in our pipeline can be accomplished using a grid search cross validation or a randomized search cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5) Create a GridSearchCV on the pipeline and save it to an object called `grid_knn`:\n",
    "- create a parameter grid that allows the search to tune the following:\n",
    "    - n = 1, 5, 10, 20, 30 nearest neighbors for KNN\n",
    "    - mean and mode strategies for imputation\n",
    "- perform a $k=5$ cross validation on our pipeline estimator.\n",
    "- gridsearch the pipeline using a scoring metric of accuracy\n",
    "- Extract the best model from the gridsearch and save it to a variable *best_pipe*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CodeGrade step1.3\n",
    "\n",
    "# Setup grid for search\n",
    "params = [{'knn__n_neighbors':[1,5,10,20,20],\n",
    "           'imp__strategy':['mean','most_frequent']\n",
    "           \n",
    "}]\n",
    "\n",
    "# Instanstiate grid search object\n",
    "grid_knn = GridSearchCV(estimator = pipe,param_grid = params,scoring='accuracy',cv=5)\n",
    "\n",
    "# Fit and get best model\n",
    "grid_knn.fit(X_train,y_train)\n",
    "best_pipe = grid_knn.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best parameters are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'imp__strategy': 'mean', 'knn__n_neighbors': 5}\n"
     ]
    }
   ],
   "source": [
    "# Run this cell without changes\n",
    "print(grid_knn.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6) Retrain `best_pipe` (your best model from cross validation) on your entire train set and predict on the true hold-out test set. \n",
    "- Save model test predictions to a variable `y_best_pred`\n",
    "- Evaluate the model accuracy on the test set and save it to a variable `tuned_test_acc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9166666666666666"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CodeGrade step1.4\n",
    "# Replace None with appropriate code\n",
    "\n",
    "# Refit to train\n",
    "pipe.set_params(knn__n_neighbors=5)\n",
    "pipe.set_params(imp=SimpleImputer(strategy='most_frequent'))\n",
    "pipe.fit(X_train,y_train)\n",
    "\n",
    "# Test set predictions and scores\n",
    "y_best_pred = pipe.predict(X_test)\n",
    "tuned_test_acc = pipe.score(X_test,y_test)\n",
    "tuned_test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Ensembles & Boosting [Suggested time: 5 minutes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forests are an ensemble tree method that aggregates the results of many randomized decision trees in order to construct a classifier/regressor that often performs better than a single decision tree. \n",
    "\n",
    "### 2.1) Short Answer: Identify the two main methods of randomization used in random forests. How are these methods employed in the random forest algorithm, and how do they help to combat the high variance that tends to characterize decision-tree models?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your  answer here\n",
    "\n",
    "`1. Bagging - involves sampling the data with replacement to create different training sets for each tree therefore reduce overfitting`\n",
    "\n",
    "`2. Subspace sampling method - randomly selecting a subset of features for each tree or split.helps where too many features can lead to overfitting`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2) Short Answer: In order to get a random forest that generalizes well, it's typically necessary to tune some hyperparameters. In the language of Sklearn's implementation, one of the most relevant hyperparameters is `max_depth`. Describe this hyperparameter and how it can factor into model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your answer here\n",
    "\n",
    "`max_depth controls depth every tree in the random forest can grow it affects performance by preventing overfiting if the max_depth is too high and if max_depth too low will underfit and fail to capture important patterns`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Natural Language Processing [Suggested time: 20 minutes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have recieved a collection of Amazon Kindle book reviews. The text has been labeled with a positive (1) or negative (0) sentiment. You are tasked with training a Sentiment Analyzer off of this free text data. First, let's load in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This book was the very first bookmobile book I...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When I read the description for this book, I c...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I just had to edit this review. This book is a...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I don't normally buy 'mystery' novels because ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This isn't the kind of book I normally read, a...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  target\n",
       "0  This book was the very first bookmobile book I...     1.0\n",
       "1  When I read the description for this book, I c...     0.0\n",
       "2  I just had to edit this review. This book is a...     1.0\n",
       "3  I don't normally buy 'mystery' novels because ...     1.0\n",
       "4  This isn't the kind of book I normally read, a...     1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this cell without changes to load in data\n",
    "sentiment_data = pd.read_csv('sentiment_analysis.csv')\n",
    "sentiment_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most important tasks before attempting to construct feature vectors and modeling is to tokenize and then normalize/preprocess the text. This can include:\n",
    "- lower casing\n",
    "- removing numerics \n",
    "- removing stopwords\n",
    "- stemming/lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1) Short Answer: Explain why stop word removal might be a useful preprocessing step prior to any given predictive task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your answer here\n",
    "\n",
    "`in order to reduce the dimensionality of dataset to only words that contain important information`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function takes in the reviewText column in our sentiment_data dataframe and preprocesses the documents. Run the following cell. This may take a minute. The preprocessed text will be saved to a new column in our sentiment_data dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell without changes to preprocess the text\n",
    "\n",
    "def tokenize_and_preprocess(reviews):\n",
    "    \n",
    "    stop_words = stopwords.words('english')\n",
    "    patt = re.compile(r'\\b(' + r'|'.join(stop_words) + r')\\b\\s+') \n",
    "\n",
    "    preproc_step1 = sentiment_data.reviewText.str.lower().str.replace(\n",
    "        r'[0-9]+', '',regex = True).str.replace(patt, '', regex = True)\n",
    "    \n",
    "    # tokeniz. result is a Pandas series of document represented as lists of tokens\n",
    "    preproc1_tokenized = preproc_step1.apply(word_tokenize)\n",
    "    \n",
    "    # inner function. takes in single document as token list.\n",
    "    # processes further by stemming and removing non-alphabetic characters\n",
    "    \n",
    "    def remove_punct_and_stem(doc_tokenized):\n",
    "        \n",
    "        stemmer = SnowballStemmer('english')\n",
    "        \n",
    "        filtered_stemmed_tok = [stemmer.stem(tok) for tok in doc_tokenized if tok.isalpha() ]\n",
    "        \n",
    "        return \" \".join(filtered_stemmed_tok)\n",
    "        \n",
    "    preprocessed = preproc1_tokenized.apply(remove_punct_and_stem)\n",
    "        \n",
    "    return preprocessed\n",
    "\n",
    "sentiment_data['preprocessed_text'] =tokenize_and_preprocess(sentiment_data.reviewText)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our text has been preprocessed and we can create a BoW matrix. You will use a TF-IDF vectorizer for this task. But before doing that:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2) Short Answer: Explain, in your own words, how the TF-IDF vectorizer assigns weights to features (tokens) in a given document. What would a high score mean for a particular word & document pair."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your answer here\n",
    "\n",
    "`it reduces weight of common words that appear in many documents and emphazing the importance of words that are more unique A high score means a word is rare across the whole dataset`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3) Save the relevant text and target to X_sent, y_sent. Use the `preprocessed_test` column created above. Train/test split with a random_state = 42. Use a 70-30 train-test split and save to the relevant variables below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CodeGrade step3.1\n",
    "# Replace None with appropriate code\n",
    "\n",
    "X_sent = sentiment_data['preprocessed_text']\n",
    "y_sent = sentiment_data['target']\n",
    "\n",
    "X_sent_train, X_sent_test, y_sent_train, y_sent_test = train_test_split(X_sent,y_sent,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4) Create a pipeline that TF-IDF vectorizes text input and then feeds it into a Multinomial Naive Bayes classifier. Ensure that tokens that are in less than 1% of the documents and in more than 90% of the documents are filtered out by our pipeline. Save the pipeline as a variable **nlp_pipe**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CodeGrade step3.2\n",
    "# Replace None with appropriate code\n",
    "\n",
    "nlp_pipe = Pipeline([\n",
    "    ('tfidf',TfidfVectorizer(min_df = 0.01,max_df=0.9)), #removes rare and common words\n",
    "    ('model',MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5) Train the pipeline and then predict on the test set. Save predicted test values as y_sent_pred and then evaluate the test accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8383333333333334"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CodeGrade step3.3\n",
    "# Replace None with appropriate code\n",
    "\n",
    "nlp_pipe.fit(X_sent_train,y_sent_train)\n",
    "y_sent_pred = nlp_pipe.predict(X_sent_test)\n",
    "test_acc = accuracy_score(y_sent_test, y_sent_pred)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6) Evaluate a confusion matrix on the predictions of the test set and save it to the variable **cfm**. Uncomment the confusion matrix display code to show."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CodeGrade step3.4\n",
    "# Replace None with appropriate code\n",
    "\n",
    "cfm = confusion_matrix(y_sent_test,y_sent_pred)\n",
    "\n",
    "ConfusionMatrixDisplay(cfm).plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7) Short Answer: Looking at the confusion matrix above, comment on how well the model is generalizing to the testing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your answer here\n",
    "\n",
    "`Model rarely misses actual positives due to the low false negatives and also model struggles to classify negatives due to the many false positives Since this is a sentiment analysis task where the cost of false negative is high, our model generalizes well on the test data`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Clustering [Suggested time: 20 minutes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1) Short Answer: In the context of clustering, what is a centroid?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your answer here\n",
    "\n",
    "`arithmetic mean of all points in a cluster,serves as representative point of the cluster`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2) Short Answer: KMeans is an algorithm used for clustering data that first randomly intializes $K$ centroids and then use a two-step iterative process (coordinate descent) to minimize the inertia cost function until convergence has been achieved. What two steps are executed during each K-Means iteration?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your answer here\n",
    "\n",
    "`1. Assigning each observation to the cluster to which it is closest`\n",
    "\n",
    "`2. Recalculate the cluster centroids bases on the points assigned to each cluster`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following data contains age and income information from a sample of customers that frequent a new mall. The mall has also creating a spending score index based on how often and how much a given customer spends at the mall. They would like to understand whether there is any structure/grouping to the customers they have. In the following, you will use KMeans to cluster the mall's customer base and identify the number of distinct groups present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Annual_Income($)</th>\n",
       "      <th>Spending_Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CustomerID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>15000</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>15000</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>16000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23</td>\n",
       "      <td>16000</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>31</td>\n",
       "      <td>17000</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Age  Annual_Income($)  Spending_Score\n",
       "CustomerID                                       \n",
       "1            19             15000              39\n",
       "2            21             15000              81\n",
       "3            20             16000               6\n",
       "4            23             16000              77\n",
       "5            31             17000              40"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this cell without changes to import data\n",
    "data_df = pd.read_csv('mall_clust.csv').set_index('CustomerID')\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 200 entries, 1 to 200\n",
      "Data columns (total 3 columns):\n",
      " #   Column            Non-Null Count  Dtype\n",
      "---  ------            --------------  -----\n",
      " 0   Age               200 non-null    int64\n",
      " 1   Annual_Income($)  200 non-null    int64\n",
      " 2   Spending_Score    200 non-null    int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 6.2 KB\n"
     ]
    }
   ],
   "source": [
    "# Run this cell without changes\n",
    "data_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Annual_Income($)</th>\n",
       "      <th>Spending_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.850000</td>\n",
       "      <td>60560.000000</td>\n",
       "      <td>50.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.969007</td>\n",
       "      <td>26264.721165</td>\n",
       "      <td>25.823522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28.750000</td>\n",
       "      <td>41500.000000</td>\n",
       "      <td>34.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>36.000000</td>\n",
       "      <td>61500.000000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>49.000000</td>\n",
       "      <td>78000.000000</td>\n",
       "      <td>73.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>70.000000</td>\n",
       "      <td>137000.000000</td>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Age  Annual_Income($)  Spending_Score\n",
       "count  200.000000        200.000000      200.000000\n",
       "mean    38.850000      60560.000000       50.200000\n",
       "std     13.969007      26264.721165       25.823522\n",
       "min     18.000000      15000.000000        1.000000\n",
       "25%     28.750000      41500.000000       34.750000\n",
       "50%     36.000000      61500.000000       50.000000\n",
       "75%     49.000000      78000.000000       73.000000\n",
       "max     70.000000     137000.000000       99.000000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this cell without changes\n",
    "data_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3) Fit a `StandardScaler` to the data and then fit a KMeans clustering model, for K = 3, to the scaled data. Use a `random_state` of 42 for KMeans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "C:\\Users\\Hp\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KMeans(n_clusters=3, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KMeans</label><div class=\"sk-toggleable__content\"><pre>KMeans(n_clusters=3, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KMeans(n_clusters=3, random_state=42)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CodeGrade step4.1\n",
    "# Replace None with appropriate code and write additional code required to fit the data\n",
    "\n",
    "# Scaling\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data_df)\n",
    "\n",
    "\n",
    "# Kmeans\n",
    "km = KMeans(n_clusters=3,random_state=42)\n",
    "\n",
    "# Fit kmeans\n",
    "km.fit(data_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4) Evaluate cluster assignments for these datapoints. Create a new dataframe `data_scaled_df` that includes your scaled data and a new column called \"cluster_label\" that indicates the cluster assignments.\n",
    "\n",
    "HINT: You can use `data_df.columns()` to set the appropriate column names for your scaled data!\n",
    "\n",
    "HINT: Start by putting your scaled data into a `pandas` DataFrame!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CodeGrade step4.2\n",
    "# Replace None with appropriate code\n",
    "\n",
    "# Dataframe for scaled\n",
    "data_scaled_df = pd.DataFrame(data_scaled,columns=data_df.columns)\n",
    "\n",
    "# New column\n",
    "data_scaled_df['cluster_label'] = km.predict(data_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5) Below we have provided code to loop through a few values of $k$ from $k=3$ to $k=9$. We fit KMeans data for each value of $k$ and generate cluster labels. Your job is to compute the Silhouette Score for each value of $k$ and add it to the the `km_dict` dictionary. Use $k$ as your dictionary key and the corresponding score as your value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "C:\\Users\\Hp\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hp\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "C:\\Users\\Hp\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hp\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "C:\\Users\\Hp\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hp\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "C:\\Users\\Hp\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hp\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "C:\\Users\\Hp\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hp\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "C:\\Users\\Hp\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hp\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "C:\\Users\\Hp\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{3: 0.357793388710272,\n",
       " 4: 0.4039582785148566,\n",
       " 5: 0.41664341513732756,\n",
       " 6: 0.4284167762892592,\n",
       " 7: 0.417231894954916,\n",
       " 8: 0.4082067042807375,\n",
       " 9: 0.41769250624076476}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CodeGrade step4.3\n",
    "# Replace None with appropriate code\n",
    "\n",
    "# Create empty dictionary to populate\n",
    "km_dict = {}\n",
    "\n",
    "# Loop through k values\n",
    "for k in range(3,10):\n",
    "    km = KMeans(n_clusters=k, random_state=42)\n",
    "    clust_pred = km.fit_predict(data_scaled)\n",
    "    # For each value k get a silhouette score\n",
    "    ss_metr = silhouette_score(data_scaled,clust_pred)  \n",
    "    # For each value of k assign a key:value pair to km_dict\n",
    "    km_dict[k] = ss_metr\n",
    "km_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the dictionary you created will be converted to a pandas Series `km_series`. We'll use pandas plotting to save the Silhouette Score vs $k$ to an ax object and display the plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run this cell without changes\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "\n",
    "km_series = pd.Series(km_dict)\n",
    "ax = km_series.plot()\n",
    "ax.set_title('Silhouette Score for k')\n",
    "ax.set_xlabel('k')\n",
    "ax.set_ylabel('SS_metric')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6) Short Answer: Based on the above plot, how many customer clusters does the SS metric suggest our data is most likely explained by?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your answer here:\n",
    "`6 customer clusters since thats where highest silhoutte score is at`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
